{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing et Classification CNN\n",
    "## Impact du Pr√©traitement sur la Reconnaissance de Panneaux Routiers\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objectifs P√©dagogiques\n",
    "\n",
    "Dans ce TP, vous allez :\n",
    "1. **Comprendre** comment le pr√©traitement d'images affecte les performances d'un mod√®le CNN\n",
    "2. **Exp√©rimenter** avec diff√©rentes techniques de filtrage du bruit (P1)\n",
    "3. **Explorer** les m√©thodes de correction de luminosit√© (P2)\n",
    "4. **Analyser** pourquoi certains pr√©traitements am√©liorent la classification et d'autres la d√©gradent\n",
    "\n",
    "### üìã √Ä propos du Dataset\n",
    "\n",
    "- **GTSRB** : German Traffic Sign Recognition Benchmark\n",
    "- **43 classes** de panneaux routiers\n",
    "- Images de taille **64x64 pixels** en couleur (RGB)\n",
    "\n",
    "### üìã Pr√©requis\n",
    "\n",
    "- Vous disposez du code du mod√®le CNN de base (P0_Model_Tensorflow.py)\n",
    "- Le dataset GTSRB complet est disponible ici : https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign \n",
    "- On travaillera avec un sous-ensemble  de 10% `./images/Train_small/` et des images de test `./images/Test/` \n",
    "- D'autres images \"hors contexte\" sont disponibles dans `./images/`\n",
    "- Le fichier `utils.py` contient des fonctions utilitaires (affichage...etc)\n",
    "- Le fichier `P0_Model_Tensorflow.py` contient le CNN (TensorFlow)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration de l'Environnement\n",
    "\n",
    "### ‚ú®Premi√®re utilisation\n",
    "\n",
    "Suivez ces √©tapes **avant** de lancer ce notebook :\n",
    "\n",
    "1. **Ouvrir un terminal** dans le dossier du projet\n",
    "2. **Cr√©er l'environnement virtuel** :\n",
    "   ```bash\n",
    "   python -m venv .venv\n",
    "   ```\n",
    "3. **Activer l'environnement** :\n",
    "   - Windows : `.venv\\Scripts\\activate`\n",
    "   - Linux/Mac : `source .venv/bin/activate`\n",
    "4. **Installer les d√©pendances** :\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "5. **Enregistrer le kernel Jupyter** (pour que Jupyter utilise cet environnement) :\n",
    "   ```bash\n",
    "   python -m ipykernel install --user --name=icv-env --display-name \"Python (ICV)\"\n",
    "   ```\n",
    "6. **Lancer Jupyter** :\n",
    "   ```bash\n",
    "   jupyter notebook\n",
    "   ```\n",
    "7. Dans le menu du notebook (Visual Studio Code) : `Select Kernel` ‚Üí `Jupyter Kernel...` ‚Üí `Python (ICV)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports r√©ussis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import show, add_noise\n",
    "from P0_Model_Tensorflow import create_model_and_evaluate\n",
    "\n",
    "# Configuration pour de meilleures visualisations\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 0 : Mod√®le de base (Sans Pr√©traitement)\n",
    "\n",
    "### üéØ √âtablir une R√©f√©rence\n",
    "\n",
    "Avant d'exp√©rimenter avec diff√©rentes techniques de pr√©traitement, nous devons **√©tablir une baseline** :\n",
    "- Mesurer les performances du mod√®le CNN sur les images **brutes** (sans aucun traitement)\n",
    "- Cette pr√©cision de r√©f√©rence nous permettra de **quantifier l'impact** de chaque technique de pr√©traitement\n",
    "\n",
    "### üèóÔ∏è Architecture du CNN\n",
    "\n",
    "Le mod√®le de base (`P0_Model_Tensorflow.py`) utilise :\n",
    "- 3 couches convolutionnelles (32 ‚Üí 64 ‚Üí 128 filtres)\n",
    "- Max pooling apr√®s chaque convolution\n",
    "- Couche dense de 128 neurones + Dropout (50%)\n",
    "- Optimiseur Adam, fonction de perte categorical crossentropy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Utiliser `create_model_and_evaluate` afin de d√©terminer la pr√©cision du mod√®le sans pr√©traitements\n",
    "# Cette fonction :\n",
    "#\n",
    "# --------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partie 1 : Filtrage du Bruit\n",
    "\n",
    "### üîç Contexte Th√©orique\n",
    "\n",
    "Le **bruit** dans les images peut provenir de :\n",
    "- Capteurs de cam√©ra (bruit thermique, photonique)\n",
    "- Compression JPEG\n",
    "- Transmission de donn√©es\n",
    "\n",
    "### üéß Types de Bruit\n",
    "\n",
    "Le bruit d√©grade la qualit√© des images en ajoutant des variations ind√©sirables aux valeurs des pixels. On distingue plusieurs types :\n",
    "\n",
    "#### 1. Bruit Gaussien (Additif)\n",
    "- **Mod√®le** : $I_{bruit√©e}(x,y) = I_{originale}(x,y) + N(0, \\sigma^2)$\n",
    "- **Caract√©ristiques** : Suit une distribution normale (courbe en cloche)\n",
    "- **Origine** : Bruit √©lectronique des capteurs, faible luminosit√©\n",
    "- **Aspect visuel** : Grain uniforme sur toute l'image\n",
    "- **Param√®tres** : Moyenne (g√©n√©ralement 0) et √©cart-type $\\sigma$\n",
    "\n",
    "#### 2. Bruit Sel et Poivre (Impulsionnel)\n",
    "- **Mod√®le** : Certains pixels prennent des valeurs extr√™mes (0 = poivre noir, 255 = sel blanc)\n",
    "- **Caract√©ristiques** : Pixels isol√©s tr√®s clairs ou tr√®s sombres\n",
    "- **Origine** : D√©fauts de transmission, pixels morts du capteur\n",
    "- **Aspect visuel** : Points blancs et noirs dispers√©s al√©atoirement\n",
    "- **Param√®tre** : Densit√© de bruit (proportion de pixels affect√©s)\n",
    "\n",
    "#### 3. Bruit de Poisson (D√©pendant du Signal)\n",
    "- **Mod√®le** : Variance proportionnelle √† l'intensit√© du signal\n",
    "- **Caract√©ristiques** : Plus visible dans les zones sombres\n",
    "- **Origine** : Nature quantique de la lumi√®re (comptage de photons)\n",
    "- **Aspect visuel** : Grain variable selon l'intensit√© lumineuse\n",
    "\n",
    "#### 4. Bruit Uniforme\n",
    "- **Mod√®le** : Distribution uniforme sur un intervalle $[a, b]$\n",
    "- **Origine** : Quantification, arrondis num√©riques\n",
    "- **Moins courant** en pratique que les bruits gaussien et impulsionnel\n",
    "\n",
    "### üîá Types de Filtres\n",
    "\n",
    "#### Filtres Lin√©aires (filtres convolutifs)\n",
    "1. **Filtre Moyenne** : Moyenne simple des pixels voisins\n",
    "2. **Filtre Gaussien** : Moyenne pond√©r√©e avec poids gaussiens\n",
    "\n",
    "#### Filtres Non Lin√©aires\n",
    "3. **Filtre M√©dian** : Remplace chaque pixel par la m√©diane de son voisinage (robuste aux valeurs aberrantes)\n",
    "4. **Filtre Bilat√©ral** : Lisse les zones homog√®nes tout en pr√©servant les contours\n",
    "5. **NLM (Non-Local Means)** : Exploite la redondance des patches dans toute l'image\n",
    "\n",
    "### üìä M√©trique d'√âvaluation : PSNR\n",
    "\n",
    "Le **PSNR (Peak Signal-to-Noise Ratio)** mesure la qualit√© de reconstruction. C'est une mesure courament utilis√©e en compression pour √©valuer la qualit√© de reconstruction. Elle peut aussi √™tre utilis√©e pour quantifier la suppression de bruit, **dans les cas o√π l'on connait une *v√©rit√© terrain*** :\n",
    "- Exprim√© en d√©cibels (dB)\n",
    "- **Plus √©lev√© = meilleur** (typiquement 20-40 dB)\n",
    "- Formule : $PSNR = 20 \\cdot \\log_{10}\\left(\\frac{MAX}{\\sqrt{MSE}}\\right)$\n",
    "\n",
    "o√π :\n",
    "- **MAX** = Valeur maximale possible d'un pixel (255 pour des images 8 bits)\n",
    "- **MSE** = Mean Squared Error (erreur quadratique moyenne) : $MSE = \\frac{1}{N} \\sum_{i=1}^{N} (I_{originale}(i) - I_{trait√©e}(i))^2$\n",
    "  - $N$ = nombre total de pixels dans l'image\n",
    "  - Plus le MSE est faible, plus les images sont similaires\n",
    "\n",
    "**Interpr√©tation** :\n",
    "- PSNR > 40 dB : Excellente qualit√©, diff√©rences quasi imperceptibles\n",
    "- 30-40 dB : Bonne qualit√©, l√©g√®res diff√©rences visibles\n",
    "- 20-30 dB : Qualit√© acceptable, diff√©rences notables\n",
    "- < 20 dB : Faible qualit√©, d√©gradation importante\n",
    "\n",
    "### üìä Estimateur de bruit\n",
    "\n",
    "Concerant notre dataset, nous ne connaissons pas de *v√©rit√© terrain* (si l'on suppose les images brui√©es, nous ne connaissons pas les images d'origines correspondante). On peut cependant estimer la quantiti√© de bruit dans une image en mesurant la variance de son laplacien.\n",
    "\n",
    "Sur notre image de test (lenna) nous allons tester diff√©rent filtre, mesurer le PSNR et la r√©duction de bruit avec notre estimateur, et v√©rifier que notre estimateur fonctionne bien.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de Bruit Synth√©tique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Utiliser la fonction `add_noise` pour ajouer du bruit gaussien et 'salt and pepper' √† l'image lenna.jpg\n",
    "# Observer les 2 types de bruits s√©par√©ment puis cumul√©s\n",
    "# (Utiliser `show` pour visualiser les images)\n",
    "#\n",
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impl√©mentation des Filtres de D√©bruitage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Appliquer les filtres suivants √† l'image bruit√©e\n",
    "# - **Moyenneur** : utiliser `cv2.blur()` avec un noyau 5√ó5\n",
    "# - **Gaussien** : utiliser `cv2.GaussianBlur()` avec un noyau 5√ó5 et sigma=1\n",
    "# - **M√©dian** : utiliser `cv2.medianBlur()` avec un noyau de taille 5\n",
    "# - **Bilat√©ral** : utiliser `cv2.bilateralFilter()` avec d=9, sigmaColor=75, sigmaSpace=75\n",
    "# - **NLM (Non-Local Means)** : utiliser `cv2.fastNlMeansDenoisingColored()` avec h=10, hColor=10\n",
    "#\n",
    "# Visualiser l'ex√©cution pour chaque type de filtre\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √âvaluation Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "#\n",
    "# Ecire une fonction qui calcule le PSNR entre une image d√©bruit√©e et son originale\n",
    "# Ecire une focntion qui estime le niveau de bruit dans une image (variance du laplacien)\n",
    "#\n",
    "# Appliquer ces 2 calculs aux diff√©rents filtres\n",
    "#\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí≠ Questionnement ?\n",
    "\n",
    "- Est ce que notre estimateur de bruit est correct ?\n",
    "- Est ce que les valeurs de PSNR et de notre estimateur sont corr√©l√©es ?\n",
    "- Est ce que les r√©sultats donn√©s par le PSNR ou l'estimateur de bruit confirme ce que vous voyez visuellement ?\n",
    "- Est ce qu'on va pouvoir se servir de l'estimateur pour estimer le bruit dans les images du dataset et choisir un filtre ?\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application sur le Dataset GTSRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Calculer le bruit moyen, minimun et maximum du dataset\n",
    "# Isoler les images correspondantes\n",
    "#\n",
    "# Tester les diff√©rents filtres sur ces 3 images\n",
    "# Observer visuellement les r√©sultats donn√©es par le meilleur et moins bon au sens de notre estimateur. \n",
    "#\n",
    "# ------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Questionnement\n",
    "\n",
    "- Les images du dataset GTSRB semblent-elles tr√®s bruit√©es ?\n",
    "- Le filtrage du bruit est-il vraiment n√©cessaire pour ce dataset ?\n",
    "- A-t-on int√©r√™t √† choisir le filtre le plus performant au sens de notre estimateur ?\n",
    "- Ou plut√¥t un filtre qui pr√©serve mieux les contour ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©ation d'un Dataset D√©bruit√© et √âvaluation CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Cr√©er 2 dossiers `.image/Train_small_denoised` et `.image/Test_denoised` contenant les images filtr√©e avec le filtre retenu\n",
    "#\n",
    "# Recalculer le bruit moyen min et max sur le dossier .image/Train_small_denoised\n",
    "#\n",
    "# ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ √âvaluation du Mod√®le sur Images D√©bruit√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "#\n",
    "# Entrainer le CNN avec ce nouveau dataset\n",
    "#\n",
    "# -----------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Analyse ?\n",
    "\n",
    "- Pourquoi cr√©er `.image/Test_denoised` ?\n",
    "- Comment expliquer ces r√©sultats ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Correction de Luminosit√©\n",
    "\n",
    "### üåì Contexte Th√©orique\n",
    "\n",
    "Les images du dataset GTSRB pr√©sentent une **grande variabilit√© de luminosit√©** :\n",
    "- Photos prises √† diff√©rents moments de la journ√©e (matin, midi, soir)\n",
    "- Conditions m√©t√©orologiques vari√©es (ensoleill√©, nuageux)\n",
    "- Ombres projet√©es par des arbres, b√¢timents, v√©hicules\n",
    "- Cam√©ras diff√©rentes avec expositions variables\n",
    "\n",
    "### Techniques de Normalisation\n",
    "\n",
    "#### 1. √âgalisation d'Histogramme Classique\n",
    "- Redistribue les intensit√©s pour couvrir toute la plage [0, 255]\n",
    "- **Avantage** : Simple et rapide\n",
    "- **Inconv√©nient** : Peut sur-amplifier le bruit dans les zones homog√®nes ou supprimer du contraste localement\n",
    "\n",
    "#### 2. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "- √âgalisation locale par tuiles (tiles)\n",
    "- Limitation du contraste (`clipLimit`) pour √©viter la sur-amplification\n",
    "- **Avantage** : Am√©liore le contraste tout en pr√©servant les d√©tails\n",
    "- **Inconv√©nient** : L√©g√®rement plus co√ªteux en calcul\n",
    "\n",
    "### üé® Espace Colorim√©trique YCrCb\n",
    "\n",
    "On travaille dans l'espace **YCrCb** plut√¥t que RGB :\n",
    "- **Y** : Luminance (information de luminosit√©)\n",
    "- **Cr, Cb** : Chrominance (information de couleur)\n",
    "\n",
    "\n",
    "La transformation RGB ‚Üí YCrCb suit les formules standardis√©es **ITU-R BT.601** :\n",
    "\n",
    "$$Y = 0.299 \\cdot R + 0.587 \\cdot G + 0.114 \\cdot B$$\n",
    "\n",
    "$$Cr = 128 + 0.500 \\cdot (R - Y) = 128 + 0.500 \\cdot R - 0.419 \\cdot G - 0.081 \\cdot B$$\n",
    "\n",
    "$$Cb = 128 + 0.500 \\cdot (B - Y) = 128 - 0.169 \\cdot R - 0.331 \\cdot G + 0.500 \\cdot B$$\n",
    "\n",
    "o√π $R$, $G$, $B \\in [0, 255]$ et $Y$, $Cr$, $Cb \\in [0, 255]$\n",
    "\n",
    "\n",
    "Le canal Y correspond √† une conversion en niveaux de gris mais avec une pond√©ration diff√©rente sur les canaux RGB d√©riv√©e de la perception humaine :\n",
    "- L'≈ìil humain est plus sensible au vert (coefficient 0.587)\n",
    "- Moyennement sensible au rouge** (0.299)\n",
    "- Peu sensible au bleu** (0.114)\n",
    "\n",
    "En changeant d'espace colorim√©trique :\n",
    "\n",
    "1. **S√©paration luminosit√©/couleur** : En isolant Y, on peut traiter la luminosit√© ind√©pendamment de la teinte\n",
    "2. **Pr√©servation des couleurs** : En modifiant uniquement Y, on normalise la luminosit√© tout en gardant les canaux Cr et Cb intacts ‚Üí les couleurs originales sont pr√©serv√©es !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impl√©mentation des Techniques de Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# Ecrire 2 fonctions pour appliquer les corrections de luminosit√© sur le canal Y\n",
    "# (utiliser cvtColor, equalizeHist, createCLAHE) \n",
    "#\n",
    "# Visualiser les 2 corrections sur l'image 2under-exposed.jpg\n",
    "#\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de la Variabilit√© de Luminosit√© dans le Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Ecrire une focntion qui permet d'estimer la luminosit√© d'une image\n",
    "# Comparer la distribution de la luminosit√© (histogramme) sur l'ensemble du dataset avant et apr√®s CLAHE\n",
    "# observer visuellement l'effet de CLAHE sur l'image la plus sombre, la plus claire et de luminosit√© moyenne\n",
    "#\n",
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Observation Cl√©\n",
    "\n",
    "Remarquez comment CLAHE **normalise** les trois images malgr√© leurs diff√©rences initiales de luminosit√©. Cela permet au CNN de se concentrer sur la **forme et le contenu** du panneau plut√¥t que sur les conditions d'√©clairage.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 - Cr√©ation d'un Dataset Normalis√© et √âvaluation CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ √âvaluation du Mod√®le avec Correction de Luminosit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusions ?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
